{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation and Search\n",
    "   - using  two years worth [real online retail transaction data](https://archive.ics.uci.edu/ml/datasets/Online+Retail+II)\n",
    "   - Key techniques applied:\n",
    "       - word/sentence embeddings (vectors)\n",
    "           - `man + king - woman = queen`\n",
    "       - inverted index\n",
    "       - cosine similarity\n",
    "       \n",
    "## Flow of Demo:\n",
    "\n",
    "### 1. Recommender System:\n",
    "\n",
    "   - Area for improvement: Recommend product to customer while browsing the app\n",
    "   - Benefit: Increase in sales and customer retention\n",
    "   - Approach: Using historical transaction data to train Word2Vec and LSTM models to give relevant/related product recommendations in app real time\n",
    "\n",
    "### 2. Search Engine:\n",
    "\n",
    "   - Area for improvement: Provide specific product options that user can buy instead of only showing the Merchants's name\n",
    "   - Benefit: Customer retention and engagement\n",
    "   - Approach: Train/Apply Doc2Vec and sentence transformer models to product and merchant's content data (name, description, reviews) to be used for calculating product relevance to the search query\n",
    "                \n",
    "### 3. Aspirations on things that can be done moving forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath_='../data/ecommerce/'\n",
    "\n",
    "from helpers.helper_funcs import (import_data,\n",
    "                                  create_customer_sessions,\n",
    "                                  make_prod_index,\n",
    "                                  read_corpus\n",
    "                                 )\n",
    "import pandas as pd\n",
    "from random import choices\n",
    "import gensim.models\n",
    "from random import randint\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>813655</th>\n",
       "      <td>573167</td>\n",
       "      <td>23264</td>\n",
       "      <td>set of 3 wooden sleigh decorations</td>\n",
       "      <td>36</td>\n",
       "      <td>2011-10-28 09:29:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>18287</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813656</th>\n",
       "      <td>573167</td>\n",
       "      <td>21824</td>\n",
       "      <td>painted metal star with holly bells</td>\n",
       "      <td>48</td>\n",
       "      <td>2011-10-28 09:29:00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>18287</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813657</th>\n",
       "      <td>573167</td>\n",
       "      <td>21014</td>\n",
       "      <td>swiss chalet tree decoration</td>\n",
       "      <td>24</td>\n",
       "      <td>2011-10-28 09:29:00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>18287</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo StockCode                          Description  Quantity  \\\n",
       "813655    573167     23264   set of 3 wooden sleigh decorations        36   \n",
       "813656    573167     21824  painted metal star with holly bells        48   \n",
       "813657    573167     21014        swiss chalet tree decoration         24   \n",
       "\n",
       "               InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "813655 2011-10-28 09:29:00       1.25       18287  United Kingdom  \n",
       "813656 2011-10-28 09:29:00       0.39       18287  United Kingdom  \n",
       "813657 2011-10-28 09:29:00       0.29       18287  United Kingdom  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = import_data()\n",
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===========================================================\n",
      "Number of unique transactions:  22190\n",
      "Number of unique customers:  4372\n",
      "Number of unique products:  3684\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n===========================================================\")\n",
    "print(\"Number of unique transactions: \", data.InvoiceNo.nunique())\n",
    "print(\"Number of unique customers: \", data.CustomerID.nunique())\n",
    "print(\"Number of unique products: \", data.StockCode.nunique())\n",
    "print(\"===========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using transaction sequences to generate related product recommendations\n",
    "   Method: Word Embeddings - numeric representations of words (product/StockCode in this case)\n",
    "   - Word2Vec (Continuous Bag of Words Model)\n",
    "       - based from context (product bought before and after)\n",
    "       - works with no labeled data\n",
    "   - Long Short Term Memory (LSTM) \n",
    "       - based on sequence of products, remember important segments (short product items sequence), forgets those aren't\n",
    "       - works when you have labeled data such as browsing behavior of user that results with a purchase or not.\n",
    "       - technically can work without labeled data (seq2seq model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender process:\n",
    "\n",
    " 1. (offline) create sequence of products bought by user (items bought by user in a browsing session, session = 1hr) this can also be sequences like browsing behavior\n",
    " 2. (offline) train embedding models (w2v/lstm)\n",
    " 3. (online) use product \"word\" vectors learned from (2) to calculate cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>StockCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12347</td>\n",
       "      <td>[85116, 22375, 71477, 22492, 22771, 22772, 227...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347</td>\n",
       "      <td>[84625A, 84625C, 85116, 20719, 22375, 22376, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12347</td>\n",
       "      <td>[22376, 22374, 22371, 22375, 20665, 23076, 217...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID                                          StockCode\n",
       "0       12347  [85116, 22375, 71477, 22492, 22771, 22772, 227...\n",
       "1       12347  [84625A, 84625C, 85116, 20719, 22375, 22376, 2...\n",
       "2       12347  [22376, 22374, 22371, 22375, 20665, 23076, 217..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_sessions = create_customer_sessions()\n",
    "customer_sessions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look up dictionary of StockCode and corresponding product description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'23166': 'medium ceramic top storage jar',\n",
       " '85116': 'black candelabra t-light holder',\n",
       " '22375': 'airline bag vintage jet set brown'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_descrip = make_prod_index()\n",
    "{k:v for i, (k, v) in enumerate(stock_descrip.items()) if i < 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec Approach (CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "40-D vectors for 3677 products\n",
      "\n",
      "Index: 0, StockCode: 85123A, Descrip: cream hanging heart t-light holder\n",
      " Vector: [-0.23690282, 0.67627496, 0.26765117, 0.39828238, 0.07714165 ... x_40] \n",
      "Index: 1, StockCode: 22423, Descrip: regency cakestand 3 tier\n",
      " Vector: [-0.11227249, 0.306507, 0.019814892, 0.4933716, -0.0047198436 ... x_40] \n"
     ]
    }
   ],
   "source": [
    "seq_fname='stock_sequences.txt'\n",
    "w2v_model = gensim.models.Word2Vec(corpus_file=datapath_+seq_fname, sg=1, min_count=1, vector_size=40)\n",
    "\n",
    "p, d = w2v_model.wv.vectors.shape\n",
    "print(\"\\n{d}-D vectors for {p} products\\n\".format(p=p, d=d))\n",
    "\n",
    "for index, word in enumerate(w2v_model.wv.index_to_key):\n",
    "    if index == 2:\n",
    "        break\n",
    "    print(\"Index: {i}, StockCode: {s}, Descrip: {d}\\n Vector: [{v} ... x_40] \".format(i=index,\n",
    "                                                                          s=word, \n",
    "                                                                          d=stock_descrip[word],\n",
    "                                                                          v=', '.join([str(i) for i in w2v_model.wv.vectors[index][:5]])\n",
    "                                                                         ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 (Online): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend related items when an item is clicked or added to cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find similar items to: StockCode: 21088, Descrip: set/6 fruit salad paper cups\n",
      "\n",
      "==============================================================================\n",
      "\t StockCode: 21096, Descrip: set/6 fruit salad  paper plates\n",
      "\t StockCode: 21090, Descrip: set/6 collage paper plates\n",
      "\t StockCode: 21087, Descrip: set/6 posies paper cups\n",
      "\t StockCode: 21089, Descrip: set/6 green spring paper cups\n",
      "\t StockCode: 20823, Descrip: gold wine goblet\n",
      "\t StockCode: 21084, Descrip: set/6 collage paper cups\n",
      "\t StockCode: 21634, Descrip: assorted mini madras notebook\n",
      "\t StockCode: 47518F, Descrip: icon placemat pop art elvis\n",
      "\t StockCode: 21394, Descrip: red polkadot beaker \n",
      "\t StockCode: 21402, Descrip: red  egg  spoon\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# stockitems=choices(w2v_model.wv.index_to_key, k=1)\n",
    "stockitems=['21088']\n",
    "print(\"Find similar items to: StockCode: {s}, Descrip: {d}\\n\".format(s=stockitems[0], d=stock_descrip[stockitems[0]]))\n",
    "print(\"==============================================================================\")\n",
    "for item in w2v_model.wv.most_similar(positive=stockitems, topn=10):\n",
    "    print(\"\\t StockCode: {s}, Descrip: {d}\".format(s=item[0], d=stock_descrip[item[0]]))\n",
    "print(\"==============================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive recommendation when multiple similar items are clicked or added to the cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==============================================================================\n",
      "\n",
      "Find similar items to:\n",
      " \n",
      "    StockCode: 90022, Descrip: edwardian drop earrings jet black\n",
      "    StockCode: 90030C, Descrip: brown kukui coconut seed necklace\n",
      "\n",
      "==============================================================================\n",
      "\t StockCode: 90030A, Descrip: spotted white natural seed necklace\n",
      "\t StockCode: 90064A, Descrip: white vintage crystal earrings\n",
      "\t StockCode: 90059F, Descrip: diamante hair grip pack/2 lt rose\n",
      "\t StockCode: 90011B, Descrip: black crystal drop earrings\n",
      "\t StockCode: 90018C, Descrip: silver black orbit drop earrings\n",
      "\t StockCode: 90001D, Descrip: antique olive green flower earrings\n",
      "\t StockCode: 90170, Descrip: daisy hair band\n",
      "\t StockCode: 90081C, Descrip: lily brooch olive colour\n",
      "\t StockCode: 90059E, Descrip: diamante hair grip pack/2 ruby\n",
      "\t StockCode: 90031, Descrip: bili nut and wood necklace\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# sim=0\n",
    "# while sim < 0.7:\n",
    "#     stockitems=choices(w2v_model.wv.index_to_key, k=2)\n",
    "#     sim=w2v_model.wv.similarity(*stockitems)\n",
    "stockitems=['90022', '90030C']\n",
    "sim=w2v_model.wv.similarity(*stockitems)\n",
    "print(\"\\n\\n==============================================================================\")\n",
    "print(\"\"\"\n",
    "Find similar items to:\\n \n",
    "    StockCode: {s}, Descrip: {d}\n",
    "    StockCode: {s1}, Descrip: {d1}\n",
    "\"\"\".format(s=stockitems[0], d=stock_descrip[stockitems[0]],\n",
    "           s1=stockitems[1], d1=stock_descrip[stockitems[1]]\n",
    "          ))\n",
    "print(\"==============================================================================\")\n",
    "for item in w2v_model.wv.most_similar(positive=stockitems, topn=10):\n",
    "    print(\"\\t StockCode: {s}, Descrip: {d}\".format(s=item[0], d=stock_descrip[item[0]]))\n",
    "print(\"==============================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM (Use other notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search capability from product descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods:\n",
    "   - inverted index\n",
    "       - list the unique \"words\" from all documents and create an index where: \n",
    "       \n",
    "           `word_1 -> (docid1, docid2, .. docid3)`\n",
    "       - [big data infrastructure for inverted index](https://www.dcs.bbk.ac.uk/~dell/teaching/cc/book/ditp/ditp_ch4.pdf)\n",
    "   - document embedding (similar concept to word vectors but applied on product description)\n",
    "       - doc2vec (PV-DBOW)\n",
    "       - sentence transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search engine indexing and document vectorisation (Offline):\n",
    "1. Create inverted index\n",
    "2. Using product decriptions, train document/sentence embedding model (doc2vec/sentence transformers)\n",
    "3. Each product item will have a corresponding vector learned from (2), this will be used when calculating relevance at query time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['medium ceramic top storage jar',\n",
       " 'black candelabra t-light holder',\n",
       " 'airline bag vintage jet set brown']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descrips = list(stock_descrip.values())\n",
    "descrips[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = descrips\n",
    "inverted_index = defaultdict(set)\n",
    "\n",
    "for docid, c in enumerate(corpus):\n",
    "    for word in c.split():\n",
    "        inverted_index[word].add(docid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Document vectors: 3684, Dimension: 40\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=40, min_count=2, epochs=40)\n",
    "\n",
    "train_corpus = read_corpus(corpus)\n",
    "\n",
    "model.build_vocab(train_corpus)\n",
    "\n",
    "print(\"Number of Document vectors: {l}, Dimension: 40\".format(l=model.corpus_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer document embedding using pre-trained sentence transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Document vectors: 3684, Dimension: 384\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "descrip_embeddings = embedder.encode(descrips, convert_to_tensor=True)\n",
    "docs, dim = descrip_embeddings.shape\n",
    "print(\"Number of Document vectors: {l}, Dimension: {d}\".format(l=docs, d=dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search retrieval process (Online):\n",
    "   1. split query in to words or ngrams:\n",
    "       - \"christmas wall decoration\" -> `[\"christmas\", \"wall\", \"decoration\"]\n",
    "   2. Using inverted index, find the product candidates\n",
    "       - candidates: product item that contains at least 1 word in the user's query\n",
    "   3. Generate document relevance scores (cosine similarity of document vectors) for the particular query\n",
    "       - relevance scores can also be generated using a ranking function (ML-learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_search(query):\n",
    "    matched_documents = set()\n",
    "    for word in query.split():\n",
    "        matches = inverted_index.get(word)\n",
    "        if matches:\n",
    "            matched_documents |= matches\n",
    "    return matched_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"avocado chair\"\n",
    "# query=\"christmas wall decoration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_indx = list(process_and_search(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===========================================================\n",
      "Query: avocado chair\n",
      "\n",
      "Most similar products:\n",
      "\n",
      "\t danish rose folding chair (Score: 0.0222)\n",
      "\t school desk and chair  (Score: -0.0740)\n",
      "\t flag of st george chair (Score: -0.0866)\n",
      "\t blue painted kashmiri chair (Score: -0.1394)\n",
      "\t pink painted kashmiri chair (Score: -0.1416)\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "query_vector = model.infer_vector(query.split())\n",
    "\n",
    "print(\"\\n\\n===========================================================\")\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nMost similar products:\\n\")\n",
    "\n",
    "matched_docs = [(i,s) for i,s in zip(match_indx, model.dv.cosine_similarities(query_vector, model.dv.vectors[match_indx]))]\n",
    "matched_docs = sorted(matched_docs, key=lambda tup: tup[1], reverse=True)\n",
    "for item, sim_score in matched_docs[:top_k]:\n",
    "    print(\"\\t {d} (Score: {s:.4f})\".format(d=corpus[item], s=sim_score))\n",
    "print(\"===========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained sentence transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Query: avocado chair\n",
      "\n",
      "Top 10 most similar products:\n",
      "\n",
      "\t school desk and chair  (Score: 0.4560)\n",
      "\t blue painted kashmiri chair (Score: 0.3810)\n",
      "\t pink painted kashmiri chair (Score: 0.3591)\n",
      "\t danish rose folding chair (Score: 0.3487)\n",
      "\t flag of st george chair (Score: 0.3128)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "search_embeddings = descrip_embeddings[match_indx]\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, search_embeddings)[0]\n",
    "idx_scores = [(i,s) for i,s in zip(match_indx, cos_scores)]\n",
    "idx_scores = sorted(idx_scores, key=lambda tup: tup[1], reverse=True)[:top_k]\n",
    "\n",
    "print(\"\\n\\n======================================================================\\n\\n\")\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nTop {n} most similar products:\\n\".format(n=top_k))\n",
    "\n",
    "for idx, score in idx_scores:\n",
    "    print('\\t', corpus[idx], \"(Score: {:.4f})\".format(score))\n",
    "print(\"======================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Query: avocado chair\n",
      "\n",
      "Top 10 most similar products:\n",
      "\n",
      "\t school desk and chair  (Score: 0.4560)\n",
      "\t retrospot padded seat cushion (Score: 0.4412)\n",
      "\t blue painted kashmiri chair (Score: 0.3810)\n",
      "\t fuschia retro bar stool (Score: 0.3759)\n",
      "\t tv dinner tray air hostess  (Score: 0.3697)\n",
      "\t pink painted kashmiri chair (Score: 0.3591)\n",
      "\t skull design tv dinner tray (Score: 0.3494)\n",
      "\t danish rose folding chair (Score: 0.3487)\n",
      "\t orange tv tray table  (Score: 0.3474)\n",
      "\t spaceboy tv dinner tray (Score: 0.3413)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "cos_scores = util.pytorch_cos_sim(query_embedding, descrip_embeddings)[0]\n",
    "top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "print(\"\\n\\n======================================================================\\n\\n\")\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nTop {n} most similar products:\\n\".format(n=top_k))\n",
    "\n",
    "for idx, score in zip(top_results.indices.tolist(), top_results.values.tolist()):\n",
    "    print('\\t', corpus[idx], \"(Score: {:.4f})\".format(score))\n",
    "print(\"======================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search pipeline\n",
    "   1. Collect and store data which includes clickstream, transactions, search, text from product title, decription, review, etc.. image\n",
    "   2. Build inverted index from products and merchants pages\n",
    "   3. Use inverted index to create a database of word - product/merchant features \n",
    "       - store data to HDFS/Clickhouse/MySQL which are scalable for big data and can be easily accessible for Data Analysts and ML Engineers\n",
    "   4. Using collected data, train models for product retrieval and recommendation using text/image/behavior data and other analytics and ML applications\n",
    "         - database for `|ngram(word) | product id | product features |`\n",
    "         - machine learning based product retrieval/recommendation\n",
    "             - train a model that gives relevance score each words to corresponding products/merchants\n",
    "             - on query time, aggregate word-document scores to produce page's query relevance score\n",
    "         - product ranking by relevance (Learning to Rank) model using product titles, description, reviews, sales as features and clicks/ratings as labels\n",
    "             - Gradient Boosted Trees (Catboost/XGboost/LightGBM) optimised using YetiRank/PairLogit/ and evaluated using Normatilised Cummulative Discounted Gain (NDCG) \n",
    "         - understand customer query better by incorporating semantic relevance inferred from using transfer learning and fine-tuning [pre-trained DNN models](https://www.sbert.net/docs/pretrained_models.html) like (BERT, GPT-3)\n",
    "         \n",
    "         <img src=\"../images/index.png\" alt=\"index\" width=\"500\"/> <img src=\"../images/ranking_model.png\" alt=\"ranking\" width=\"500\"/> \n",
    "   5. Continuously update the database and index of product, customer and merchant data and transactions\n",
    "   6. Use customer feedback from clickstream and ratings to evaluate and improve models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/query_process.png\" alt=\"query process\" width=\"500\" lenght=\"100\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_py39",
   "language": "python",
   "name": "conda_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
