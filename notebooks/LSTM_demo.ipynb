{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.helper_funcs import (import_data,\n",
    "                                  create_customer_sessions,\n",
    "                                  make_prod_index\n",
    "                                 )\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Embedding\n",
    "from random import choices\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != 'GPU'\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>StockCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12347</td>\n",
       "      <td>[85116, 22375, 71477, 22492, 22771, 22772, 227...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID                                          StockCode\n",
       "0       12347  [85116, 22375, 71477, 22492, 22771, 22772, 227..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_sessions = create_customer_sessions()\n",
    "customer_sessions.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FYI: LSTM is not expected to work well in this data because training label was just some random assignment of 0's and 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-09 22:01:25.184752: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-09 22:01:25.184901: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "332/332 [==============================] - 8s 22ms/step - loss: 0.6933 - auc: 0.5014 - val_loss: 0.6936 - val_auc: 0.5081\n",
      "Epoch 2/3\n",
      "332/332 [==============================] - 8s 23ms/step - loss: 0.6781 - auc: 0.6021 - val_loss: 0.7033 - val_auc: 0.5046\n",
      "Epoch 3/3\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.6212 - auc: 0.7111 - val_loss: 0.7471 - val_auc: 0.4977\n"
     ]
    }
   ],
   "source": [
    "stock_codes = customer_sessions.StockCode.apply(lambda x: ' '.join(x))\n",
    "\n",
    "vocabulary_size = 3684\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(stock_codes)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(stock_codes)\n",
    "data = pad_sequences(sequences, maxlen=50)\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(vocabulary_size, 40, input_length=50))\n",
    "model_lstm.add(LSTM(40, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    model_lstm.fit(data, \n",
    "                   np.random.randint(low=0, high=2, size=len(data)), #random for the sake of demo but should/could be trained on \n",
    "                                                                    #sequences of products browsed that end up to sale\n",
    "                   validation_split=0.4, \n",
    "                   epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Model approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "40-D vectors for 3684 products\n",
      "\n",
      "Index: 1, StockCode: 85123a, Descrip: cream hanging heart t-light holder\n",
      " Vector: [0.05075116, -0.04993635, -0.014939041, 0.019268792, -0.047574632 ... x_40] \n",
      "Index: 2, StockCode: 22423, Descrip: regency cakestand 3 tier\n",
      " Vector: [-0.045232665, 0.014394014, -0.008984042, -0.034486726, 0.02907243 ... x_40] \n"
     ]
    }
   ],
   "source": [
    "lstm_embds = model_lstm.layers[0].get_weights()[0]\n",
    "\n",
    "p, d = lstm_embds.shape\n",
    "print(\"\\n{d}-D vectors for {p} products\\n\".format(p=p, d=d))\n",
    "\n",
    "stock_descrip = make_prod_index()\n",
    "\n",
    "for index, word in tokenizer.index_word.items():\n",
    "    if index == 3:\n",
    "        break\n",
    "    print(\"Index: {i}, StockCode: {s}, Descrip: {d}\\n Vector: [{v} ... x_40] \".format(i=index,\n",
    "                                                                          s=word, \n",
    "                                                                          d=stock_descrip[word.upper()],\n",
    "                                                                          v=', '.join([str(i) for i in lstm_embds[index][:5]])\n",
    "                                                                         ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations doesn't make sense since we don't have a real labeled data for the sequences\n",
    " - with real labels, LSTM should be able learn (product) vectors using sequential browsing pattern that leads to a sale (or no sale)\n",
    " - this model could be trained to make recommendations that more likely end to a sale\n",
    " - the model could be applied in real time, while customer browse/click thru a sequence of products the recommendations will nudge them to purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==============================================================================\n",
      "\n",
      "Find similar items to:\n",
      " \n",
      "    StockCode: 22396, Descrip: magnets pack of 4 retro photo\n",
      "\n",
      "==============================================================================\n",
      "\t StockCode: 23185, Descrip: french style storage jar jam\n",
      "\t StockCode: 22299, Descrip: pig keyring with light & sound \n",
      "\t StockCode: 79066k, Descrip: retro mod tray\n",
      "\t StockCode: 16045, Descrip: popart wooden pencils asst\n",
      "\t StockCode: 84976, Descrip: rectangular shaped mirror\n",
      "\t StockCode: 72349b, Descrip: set/6 purple butterfly t-lights\n",
      "\t StockCode: 20932, Descrip: pink pot plant candle\n",
      "\t StockCode: 21509, Descrip: cowboys and indians birthday card \n",
      "\t StockCode: 21894, Descrip: potting shed seed envelopes\n",
      "\t StockCode: 20769, Descrip: daisy journal \n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "stockitem=np.random.randint(tokenizer.num_words)\n",
    "\n",
    "print(\"\\n\\n==============================================================================\")\n",
    "print(\"\"\"\n",
    "Find similar items to:\\n \n",
    "    StockCode: {s}, Descrip: {d}\n",
    "\"\"\".format(s=tokenizer.index_word[stockitem].upper(), \n",
    "           d=stock_descrip[tokenizer.index_word[stockitem].upper()]\n",
    "          ))\n",
    "print(\"==============================================================================\")\n",
    "for item_index in list(reversed(np.argsort(cosine_similarity(lstm_embds[stockitem].reshape(1, -1), \n",
    "                                                             lstm_embds))[0]))[:11]:\n",
    "    if item_index!= stockitem:\n",
    "        print(\"\\t StockCode: {s}, Descrip: {d}\".format(s=tokenizer.index_word[item_index], \n",
    "                                                       d=stock_descrip[tokenizer.index_word[item_index].upper()]))\n",
    "print(\"==============================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==============================================================================\n",
      "\n",
      "Find similar items to:\n",
      " \n",
      "    StockCode: 23075, Descrip: double ceramic parlour hook\n",
      "    StockCode: 21058, Descrip: party invites woodland\n",
      "\n",
      "==============================================================================\n",
      "\t StockCode: 22334, Descrip: dinosaur party bag + sticker set\n",
      "\t StockCode: 22217, Descrip: t-light holder hanging lace\n",
      "\t StockCode: 22938, Descrip: cupcake lace paper set 6\n",
      "\t StockCode: 84792, Descrip: enchanted bird coathanger 5 hook\n",
      "\t StockCode: 79403, Descrip: frosted white base \n",
      "\t StockCode: 22129, Descrip: party cones candy tree decoration\n",
      "\t StockCode: 22737, Descrip: ribbon reel christmas present \n",
      "\t StockCode: 22107, Descrip: pizza plate in box\n",
      "\t StockCode: 22496, Descrip: set of 2 round tins dutch cheese\n",
      "\t StockCode: 23528, Descrip: spaceboy wall art\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "sim=0\n",
    "while sim < 0.7:\n",
    "    idxs=np.random.randint(tokenizer.num_words, size=2)\n",
    "    stockitems=lstm_embds[idxs]\n",
    "    sim=cosine_similarity(stockitems)[0,1]\n",
    "\n",
    "print(\"\\n\\n==============================================================================\")\n",
    "print(\"\"\"\n",
    "Find similar items to:\\n \n",
    "    StockCode: {s}, Descrip: {d}\n",
    "    StockCode: {s1}, Descrip: {d1}\n",
    "\"\"\".format(s=tokenizer.index_word[idxs[0]].upper(), \n",
    "           d=stock_descrip[tokenizer.index_word[idxs[0]].upper()],\n",
    "           s1=tokenizer.index_word[idxs[1]].upper(), \n",
    "           d1=stock_descrip[tokenizer.index_word[idxs[1]].upper()]\n",
    "          ))\n",
    "print(\"==============================================================================\")\n",
    "for item_index in list(reversed(np.argsort(cosine_similarity(stockitems.mean(axis=0).reshape(1, -1), \n",
    "                                                             lstm_embds))[0]))[:12]:\n",
    "    if item_index not in idxs:\n",
    "        print(\"\\t StockCode: {s}, Descrip: {d}\".format(s=tokenizer.index_word[item_index], \n",
    "                                                       d=stock_descrip[tokenizer.index_word[item_index].upper()]))\n",
    "print(\"==============================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m1",
   "language": "python",
   "name": "m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
